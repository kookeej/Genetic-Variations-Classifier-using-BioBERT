ğŸ† Personalized Medicine: Redefining Cancer Treatment
===
### *Kaggleâ˜ Predict the effect of Genetic Variants to enable Personalized Medicine!ğŸ˜€*     
![image](https://user-images.githubusercontent.com/74829786/177875738-e780ded5-07b7-4b56-b2b5-d1d999bbd03f.png)
Kaggle researchë¡œ ë‚˜ì˜¨ í”„ë¡œì íŠ¸ë¡œ, **ê°œì¸ ë§ì¶¤í˜• ì˜ì•½í’ˆ**ì„ ì´ìš©í•˜ê¸° ìœ„í•´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.    
ë¨¼ì € ì—¼ê¸° ì„œì—´ì´ ë¶„ì„ë˜ë©´, ì•” ì¢…ì–‘ì€ ìˆ˜ì²œ ê°œì˜ ìœ ì „ì  ëŒì—°ë³€ì´ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì œëŠ” ì¢…ì–‘ ì„±ì¥ì— ê¸°ì—¬í•˜ëŠ” ëŒì—°ë³€ì´ì™€ ì¤‘ì„± ëŒì—°ë³€ì´ë¥¼ êµ¬ë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.    
**í˜„ì¬ë¡œì¨ëŠ” ì´ ìœ ì „ì ëŒì—°ë³€ì´ì— ëŒ€í•œ í•´ì„ì€ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì„ìƒ ë³‘ë¦¬í•™ìëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„ìƒ ë¬¸í—Œ ê·¼ê±°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ë‹¨ì¼ ìœ ì „ì ëŒì—°ë³€ì´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê²€í† í•˜ê³  ë¶„ë¥˜í•´ì•¼í•˜ê³ , ì´ëŠ” ë§¤ìš° ì†Œëª¨ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤.**    

**ë”°ë¼ì„œ MSKCCëŠ” ìœ ì „ì  ë³€ì´ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•˜ê¸° ìœ„í•´ Kaggleê³¼ í˜‘ë ¥í•˜ì—¬ ì´ Competitionì„ ì‹œí–‰í•˜ì˜€ìŠµë‹ˆë‹¤.**


                                                                                                                   
***

## 1. Dataset
* ë°ì´í„°ì…‹ì˜ ì „ì²´ í¬ê¸°ëŠ” ì´ 3316ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œëŠ” ì ì€ ìˆ˜ì…ë‹ˆë‹¤.
* í•˜ë‚˜ì˜ ë¬¸ì„œë‹¹ ìµœëŒ€ ì‹­ë§Œ ê¸€ìê¹Œì§€ ë“¤ì–´ìˆê¸° ë•Œë¬¸ì— ìµœëŒ€ í† í°ìˆ˜ê°€ 512ì¸ BERTë¥¼ ì‚¬ìš©í•˜ê¸°ì—ëŠ” ë¬´ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤.
* ë”°ë¼ì„œ **í•œ í…ìŠ¤íŠ¸ë¥¼ 2000ê¸€ì(ëŒ€ëµ 512í† í° ì´ë‚´)ë¡œ ìª¼ê°œ ìƒˆë¡­ê²Œ ë¬¸ì„œë¥¼ ë§Œë“¤ì–´** Data augmentationê³¼ BERT max token length ë¬¸ì œë¥¼ ë™ì‹œì— í•´ê²°í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ ë°ì´í„°ì…‹ ìˆ˜ëŠ” 3316ì—ì„œ 107352ë¡œ ì¦ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.
```python
# ê° í…ìŠ¤íŠ¸ëŠ” Gene, Variation ì •ë³´ë¥¼ ê°–ë„ë¡ í•œë‹¤.
# special token </s>ë¡œ êµ¬ë¶„ì§€ì–´ì¤€ë‹¤.
dataset['texts'] = " </s> " + dataset['Gene'] + " </s> " + dataset['Variation'] + ' </s> ' + dataset['TEXT']
```

```python
# ë°ì´í„°ì…‹ì„ ê¸€ììˆ˜ 2000ì„ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë‘ ë‚˜ëˆ  ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€í•œë‹¤.
n = 2000
new_df = pd.DataFrame(columns={'ID', 'TEXT', 'NEW_TEXT', 'LABELS', 'CLASS'})
for i in range(len(dataset)):
    result = [dataset.iloc[i]['TEXT'][k * n:(k + 1) * n] for k in range((len(dataset.iloc[i]['TEXT']) + n - 1) // n )] 
    for j in range(len(result)):
        item = {'ID': dataset.iloc[i]['ID'], 'TEXT': result[j], 
                'NEW_TEXT': "</s> " + dataset.iloc[i]['Gene'] + " </s> " + dataset.iloc[i]['Variation'] + " </s> " + result[j],
                'LABELS': dataset.iloc[i]['labels'],
                'CLASS': dataset.iloc[i]['Class']}
        new_df = new_df.append(item, ignore_index=True)
```
* ClassëŠ” 1, 2, 3...ê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ìˆëŠ”ë°, one-hot encodingì„ í†µí•´ ë ˆì´ë¸”ì„ ìƒˆë¡œ ì •ì˜í•´ì¤ë‹ˆë‹¤.
* ìµœì¢…ì ì¸ Dataframeì˜ ëª¨ìŠµì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
![image](https://user-images.githubusercontent.com/74829786/177877343-6aaaba2d-4ffc-4c88-997d-c3d02b15ca66.png)



* ì‹¤ì œë¡œ ì‹¤í—˜ì„ ì§„í–‰í•´ë³´ë‹ˆ data augmentationì„ ì§„í–‰í•œ ë°ì´í„°ì…‹ì„ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì´ ê·¸ë ‡ì§€ ì•Šì€ ëª¨ë¸ë³´ë‹¤ ë” ì„±ëŠ¥ì´ ì¢‹ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.    
![image](https://user-images.githubusercontent.com/74829786/177870405-2029e627-8adc-470a-bccd-7a7d8be5223b.png)


## 2. Model
* Biomedical textë¥¼ ìœ„í•œ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì¸ [BioBERT-Large v1.1](https://github.com/dmis-lab/biobert)ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
* ID Embeddingì„ ì ìš©í•œ ëª¨ë¸ê³¼ ì ìš©í•˜ì§€ ì•Šì€ ëª¨ë¸ì„ ì„¤ê³„í•˜ì˜€ìŠµë‹ˆë‹¤.


## 3. Experiments
```
epochs: 10
learning rate: 1e-4
optimizer: Adam
loss fucntion: MSE
```
* **ID Embeddingì„ ì ìš©í•œ ê²½ìš°**    
![image](https://user-images.githubusercontent.com/74829786/177868532-eb173fd2-4a94-46e6-a3c7-782a6c819e89.png)

* **ID Embeddingì„ ì ìš©í•˜ì§€ ì•Šì€ ê²½ìš°**    
![image](https://user-images.githubusercontent.com/74829786/177868684-1ef4fbeb-771d-4435-8844-ca24e6a7ccf8.png)

* ID Embeddingì„ ì ìš©í•œ ê²½ìš°ê°€ ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ë³´ë‹¤ ì„±ëŠ¥ì´ ë” ë›°ì–´ë‚˜ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    
![image](https://user-images.githubusercontent.com/74829786/177868219-7c2e4a80-b301-401e-aafa-97fe1669eff7.png)

***

### ğŸ’¡ ì‹¤í–‰ ë°©ë²•

#### 1. Data Preprocessing
```python
$ python preprocessing.py \
  --train_path =TRAIN_DATASET_PATH
  --test_size  =0.1
  --max_len    =MAX_TOKEN_LENGTH  # 256
```

#### 2. Training
```python
$ python train.py \
  --epochs =10
```
